# Install Ollama (local LLM runner)

Download from https://ollama.ai/download and follow OS instructions.

Quick verify after install:
```bash
ollama version
```

To pull a model (example):
```bash
ollama pull llama3
```

If you prefer using OpenAI instead of local models, the code includes simple switches.
